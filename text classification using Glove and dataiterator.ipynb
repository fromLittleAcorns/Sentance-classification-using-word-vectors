{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Notebook to look at a how to use a word vector approach to catagorise sentances.\n",
    "\n",
    "This is to help with analysing and assessing transaction data from a company based upon the \n",
    "description of the transaction.\n",
    "\n",
    "The approach is to use a pre-trained set of word vectors - in this case the GloVe set 6.B with each vector being of \n",
    "length 300.\n",
    "\n",
    "In this analysis the approach is to define a fixed sentance length and pad sentances where they are less than this.\n",
    "\n",
    "I have tried lengths of 5 to 10, and 6 or 7 seems to work best. At present I am padding the sentances in my routine, \n",
    "I intend to see how well the padding in the pytorch embedding layer works and whether this is any better since\n",
    "I am not sure if the padding is having a detrimental effect upon the analysis.\n",
    "\n",
    "After the embedding layer I am using a simple 3 level neural network, the first two layers with rectified linear and \n",
    "then finally a softmax output\n",
    "\n",
    "The previous analysis achieved accuracy of 88.9% on training data but 66.2% on the test data using a simple \n",
    "bag of words approach.\n",
    "\n",
    "The present analysis gives me 89% on the training data and 92% on the test data, hence it is a big improvement in the analysis of the untrained datasets.  More could be done but the actual data itself needs some work and some of the catagories are not very well represented.\n",
    "\n",
    "An improvement I would like to try at some point is to use the natural language tool kit and \n",
    "stemmer from the nltk library, however, I think this model is fundamentally limited and so won't \n",
    "do so with this version\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from myData import Dataset\n",
    "from myData import DataLoader\n",
    "#from torchtext import data as t_data\n",
    "#from torchtext import utils\n",
    "from torchtext.vocab import load_word_vectors\n",
    "import numpy as np\n",
    "#import re\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import word_processing as wp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# System parameters\n",
    "my_file_path='johnrichmond/Dropbox/Machine Learning/text classification/Andrew/'\n",
    "csv_file_name='Payment items.csv'\n",
    "\n",
    "stop_list= set(\"for a c e do h i if is it in g o p or r t u v y 's ' of the and mr ms to nd we\".\n",
    "               split())\n",
    "pad='<pad>'\n",
    "\n",
    "remove_single_words=True\n",
    "max_sent_length=7\n",
    "min_freq=1\n",
    "use_subset_data=True\n",
    "max_cases=30000\n",
    "\n",
    "# only there are catagories 1-14 are valid, all others should be rejected\n",
    "\n",
    "min_cat=0\n",
    "max_cat=13\n",
    "num_cat=max_cat+1\n",
    "label_to_idx={\"Activity\":0, \n",
    "              \"Course\": 1,\n",
    "              \"Exam resit\":2,\n",
    "              \"Fees or contribution\": 3,\n",
    "              \"Letting\": 4,\n",
    "              \"Meal\":5,\n",
    "              \"Patents evening\": 6,\n",
    "              \"School bus\":7,\n",
    "              \"Tickets\":8,\n",
    "              \"Trip\":9,\n",
    "              \"Tuition\":10,\n",
    "              \"Uniform\":11,\n",
    "              \"Wraparound care\":12,\n",
    "              \"Other\":13\n",
    "             }\n",
    "load_word_vector_set='glove.6B'\n",
    "word_vector_length=300\n",
    "word_vector_path='johnrichmond/Dropbox/Machine Learning/text classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis Hyper parameters\n",
    "batch_size=32\n",
    "no_epochs=300\n",
    "HL1_size=200\n",
    "HL2_size=80\n",
    "HL3_size=30\n",
    "lr=0.006\n",
    "momentum=0.2\n",
    "nesterov=False\n",
    "L2=0.000\n",
    "val_percentage=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the file paths the same whether using Mac or Linux\n",
    "if sys.platform == 'darwin':\n",
    "    start='/Users/'\n",
    "else: start='/home/'\n",
    "    \n",
    "file_name=my_file_path+csv_file_name\n",
    "txt_file=start+file_name\n",
    "word_vec_path=os.path.join(start,word_vector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_list={\"years\":\"year\", \"yr\":\"year\", \"wks\":\"week\",\"tickets\": \"ticket\",\n",
    "              \"terms\":\"term\", \"students\":\"student\",\"pupils\":\"pupil\",\"meals\": \"meal\",\n",
    "              \"lakes\":\"lake\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to measure classification accuracy - move to module once programme \n",
    "# is operating\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    # The next line is not needed in this case since it is done prior to the call\n",
    "    #_, pred = output.topk(maxk, 1, True, True) # topk is torch function to return highest values in array\n",
    "    pred = output.t()  #Transpose\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    \"\"\"\n",
    "    Note - the expand is a torch command to expend one tensor to the size of another\n",
    "    target os a one D tensor. target.view(1,-1) reshapes the tensor.  The -1 means this \n",
    "    is chosen by the software to get the right total size.  The first 1 indicates the number \n",
    "    of rows to use.\n",
    "    The net outcome is an array with one column of length maxk for each target value.  \n",
    "    The entire column is filled with the target value to facilitate easy comparison. \n",
    "    The correct array then contains an array with true wherever the tar\n",
    "    \"\"\"\n",
    "    #get value matches the prediction\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)    # The nomeclature[:k] returns the top k rows Since\n",
    "                                                           # there is no second array we get the every column.\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sentances to catagorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(txt_file,'rU') as file_obj:\n",
    "    f_data=[]\n",
    "    num=0\n",
    "    lines=[]\n",
    "    reader=csv.reader(file_obj)\n",
    "    for line in reader:\n",
    "        if reader.line_num<>1:\n",
    "    #       with col in line:\n",
    "            text_str=line[0]\n",
    "            catagory=line[15]\n",
    "            if wp.is_integer(catagory):\n",
    "                f_data.append([text_str,int(catagory)])\n",
    "                num=num+1\n",
    "        if reader.line_num>max_cases and use_subset_data: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentance length: 22 words\n"
     ]
    }
   ],
   "source": [
    "# All data loaded, will now process each line of data\n",
    "# Initially remove numbers and punctuation\n",
    "sentances=[]\n",
    "catagories=[]\n",
    "catagory=[]\n",
    "identity=np.identity(num_cat)\n",
    "for row in f_data:\n",
    "    row[0]=wp.clean_str(row[0])\n",
    "    row[0]=wp.rem_numbers(row[0])# Done separately since I might not always want to do this\n",
    "\n",
    "    if row[0] in (None, \"\"):\n",
    "        # row rejected\n",
    "        continue\n",
    "    elif row[1] <1 or row[1]> num_cat or row[1] in (None, \"\"):\n",
    "        continue\n",
    "    sentance=row[0].split(\" \")\n",
    "    # remove stop list words\n",
    "    sentance=wp.remove_stop_words(sentance,stop_list)\n",
    "    sentance=wp.replace_similar_words(sentance,replace_list)\n",
    "    if len(sentance)==0: continue\n",
    "    row[1]=row[1]-1   \n",
    "    \n",
    "    # Getting to this point implies the row is ok and still has valid words, therefore will add\n",
    "    sentances.append(sentance)\n",
    "    catagories.append(identity[row[1]-1,:])\n",
    "    catagory.append(row[1])\n",
    "    \n",
    "# Remove single words  \n",
    "if remove_single_words==True:\n",
    "    final_sentances=[]\n",
    "    final_catagories=[]\n",
    "    final_catagory=[]\n",
    "    word_counts = Counter(itertools.chain(*sentances))\n",
    "    new_sentances=[[word for word in sentance if word_counts[word]>1] \n",
    "                    for sentance in sentances]\n",
    "    #Remove empty entries from both sentances and catagories\n",
    "    for index,sentance in enumerate(new_sentances):\n",
    "        if len(sentance)<>0:\n",
    "            final_sentances.append(sentance)\n",
    "            final_catagories.append(catagories[index])\n",
    "            final_catagory.append(catagory[index])\n",
    "    sentances=final_sentances\n",
    "    catagories=final_catagories\n",
    "    catagory=final_catagory\n",
    "    \n",
    "# Identify the longest sentance\n",
    "max_length=0\n",
    "for sentance in sentances:\n",
    "    if len(sentance)> max_length: max_length=len(sentance)\n",
    "print \"Maximum sentance length: {} words\".format(max_length)\n",
    "\n",
    "# Pad sentances to maximum length\n",
    "if max_sent_length<>0:\n",
    "    pad_to=max_sent_length\n",
    "else:\n",
    "    pad_to=max_length\n",
    "for sentance in sentances:\n",
    "    len_sent=len(sentance)\n",
    "    if len_sent<pad_to:\n",
    "        for pos in range(len_sent,pad_to):\n",
    "            sentance.append(pad)\n",
    "\n",
    "for i in range(len(sentances)):\n",
    "    sentances[i]=sentances[i][0:max_sent_length]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from /Users/johnrichmond/Dropbox/Machine Learning/text classification/glove.6B.300d.pt\n"
     ]
    }
   ],
   "source": [
    "# Make use of the use of the pytext Vocab class \n",
    "from torchtext import vocab\n",
    "test=Counter(itertools.chain(*sentances))\n",
    "v=vocab.Vocab(test,wv_type=load_word_vector_set,wv_dim=300, unk_init='random', specials=[pad], min_freq=min_freq)\n",
    "\n",
    "# We now have v.itos which containes an ordered list of words\n",
    "# v.stoi which is a disctionary that links a word to an index\n",
    "# The number of words is given by len(v.itos)\n",
    "vocab_size=len(v.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now need to shuffle the input data\n",
    "from random import shuffle\n",
    "no_sentances=len(catagory)\n",
    "# Create index and shuffle\n",
    "shuffle_idx=[i for i in range(no_sentances)]\n",
    "shuffle(shuffle_idx)\n",
    "new_sentances=[]\n",
    "new_catagory=[]\n",
    "for idx in shuffle_idx:\n",
    "    new_sentances.append(sentances[idx])\n",
    "    new_catagory.append(catagory[idx])\n",
    "# for now will save the originals but do not need to in future\n",
    "sentances_bak=sentances[:]\n",
    "catagory_bak=catagory[:]\n",
    "sentances=new_sentances\n",
    "catagory=new_catagory\n",
    "\n",
    "# The lists are now shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid sentances: 16370\n"
     ]
    }
   ],
   "source": [
    "# will setup simple batches and sets for now\n",
    "total_sentances=len(sentances)\n",
    "total_batches=int(total_sentances/batch_size)\n",
    "train_batches=int(total_batches*0.8)\n",
    "val_batches=total_batches-train_batches\n",
    "\n",
    "print \"Total valid sentances: {:d}\".format(total_sentances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sent_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This is a very simplified version of a Pytorch dataset that I am using with my own \n",
    "    bespoke versions of the Pytorch dataiterator since I could not get the proper versions\n",
    "    to work and this seemed the easiest way.  It does not support multi workers, transforms etc\n",
    "    \n",
    "    Args:\n",
    "        sentances: expected to be a list of sentnaces, each containing a list of words \n",
    "                    as strings\n",
    "        catagory: the corresponding catagory number of each sentance\n",
    "        word_to_idx: a dictionary linking a word to an index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentances, catagory, word_to_idx):\n",
    "\n",
    "        self.sentances = sentances\n",
    "        self.catagory = catagory\n",
    "        self.word_to_idx = word_to_idx\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            context_idxs: a list of the word indexes in the sentance corresponding to the \n",
    "            sentance index\n",
    "            catagory[index]: the catagory of the sentance\n",
    "        \"\"\"\n",
    "        context_idxs=(map(lambda w: self.word_to_idx[w], sentances[index]))\n",
    "             \n",
    "        #print \"sentance nums= \",sentance\n",
    "\n",
    "        return context_idxs, catagory[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.catagory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds=sent_dataset(sentances[0:train_batches*batch_size],\n",
    "                      catagory[0:train_batches*batch_size],\n",
    "                      v.stoi)\n",
    "val_ds=sent_dataset(sentances[train_batches*batch_size:total_batches*batch_size],\n",
    "                      catagory[train_batches*batch_size:total_batches*batch_size],\n",
    "                      v.stoi)\n",
    "train_loader=DataLoader(dataset=train_ds,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)\n",
    "val_loader=DataLoader(dataset=val_ds,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextClassifier_simple(nn.Module):\n",
    "    def __init__(self, catagories, vocab_size, sent_length,embedding_dim, HL1_size, HL2_size):\n",
    "        super(TextClassifier_simple, self).__init__()\n",
    "        self.embeddings=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1=nn.Linear(embedding_dim*sent_length,HL1_size)\n",
    "        self.dropout=nn.Dropout()\n",
    "        self.linear2=nn.Linear(HL1_size, HL2_size)\n",
    "        self.linear3=nn.Linear(HL2_size, catagories)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #embeds=self.embeddings(inputs).view(1,-1)\n",
    "        embeds=self.embeddings(inputs).view(len(inputs),-1)\n",
    "        out=F.relu(self.linear1(embeds))\n",
    "        out=self.dropout(out)\n",
    "        out=F.relu(self.linear2(out))\n",
    "        out=self.linear3(out)\n",
    "        log_probs=F.log_softmax(out)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define classifier, optimiser and prevent modification of the word vector weights\n",
    "losses=[]\n",
    "loss_function=nn.NLLLoss()\n",
    "model=TextClassifier_simple(num_cat, vocab_size, pad_to, word_vector_length, HL1_size, HL2_size)\n",
    "optimizer=optim.SGD(model.parameters(),lr, weight_decay=L2, momentum=momentum, nesterov=nesterov)\n",
    "model.embeddings.weight.data.copy_(v.vectors)\n",
    "model.embeddings.weight.requires_grad = False\n",
    "loss_function.parameters = filter(lambda p: p.requires_grad, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss= \n",
      " 811.1234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 1, Loss= \n",
      " 741.5076\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 2, Loss= \n",
      " 664.9062\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 3, Loss= \n",
      " 604.8054\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 4, Loss= \n",
      " 564.0308\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 5, Loss= \n",
      " 535.8111\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 6, Loss= \n",
      " 515.1380\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 7, Loss= \n",
      " 500.0435\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 8, Loss= \n",
      " 481.6049\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 9, Loss= \n",
      " 471.8219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 10, Loss= \n",
      " 456.4569\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 11, Loss= \n",
      " 449.1542\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 12, Loss= \n",
      " 435.5252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 13, Loss= \n",
      " 431.2939\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 14, Loss= \n",
      " 420.8241\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 15, Loss= \n",
      " 417.2932\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 16, Loss= \n",
      " 410.5732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 17, Loss= \n",
      " 401.3507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 18, Loss= \n",
      " 397.3323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 19, Loss= \n",
      " 392.1477\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 20, Loss= \n",
      " 386.9507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 21, Loss= \n",
      " 382.4657\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 22, Loss= \n",
      " 376.4735\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 23, Loss= \n",
      " 374.2408\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 24, Loss= \n",
      " 370.7749\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 25, Loss= \n",
      " 365.8584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 26, Loss= \n",
      " 362.5965\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 27, Loss= \n",
      " 358.5144\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 28, Loss= \n",
      " 355.0985\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 29, Loss= \n",
      " 349.4259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 30, Loss= \n",
      " 350.4254\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 31, Loss= \n",
      " 347.6332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 32, Loss= \n",
      " 342.1928\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 33, Loss= \n",
      " 337.0499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 34, Loss= \n",
      " 335.4918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 35, Loss= \n",
      " 333.7696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 36, Loss= \n",
      " 327.3244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 37, Loss= \n",
      " 327.4155\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 38, Loss= \n",
      " 324.8204\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 39, Loss= \n",
      " 322.1362\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 40, Loss= \n",
      " 318.6174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 41, Loss= \n",
      " 317.2008\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 42, Loss= \n",
      " 315.4757\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 43, Loss= \n",
      " 310.8386\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 44, Loss= \n",
      " 306.8342\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 45, Loss= \n",
      " 307.4794\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 46, Loss= \n",
      " 307.4941\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 47, Loss= \n",
      " 304.7894\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 48, Loss= \n",
      " 297.8760\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 49, Loss= \n",
      " 295.7848\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 50, Loss= \n",
      " 295.1397\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 51, Loss= \n",
      " 295.9767\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 52, Loss= \n",
      " 292.5818\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 53, Loss= \n",
      " 291.7705\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 54, Loss= \n",
      " 290.0965\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 55, Loss= \n",
      " 286.2175\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 56, Loss= \n",
      " 285.8975\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 57, Loss= \n",
      " 283.3617\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 58, Loss= \n",
      " 280.9380\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 59, Loss= \n",
      " 279.6425\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 60, Loss= \n",
      " 278.2398\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 61, Loss= \n",
      " 277.8954\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 62, Loss= \n",
      " 272.6950\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 63, Loss= \n",
      " 274.7087\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 64, Loss= \n",
      " 268.9554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 65, Loss= \n",
      " 269.5184\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 66, Loss= \n",
      " 265.8367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 67, Loss= \n",
      " 267.2621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 68, Loss= \n",
      " 262.6931\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 69, Loss= \n",
      " 262.7004\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 70, Loss= \n",
      " 260.6262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 71, Loss= \n",
      " 258.9219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 72, Loss= \n",
      " 257.9078\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 73, Loss= \n",
      " 256.2188\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 74, Loss= \n",
      " 254.0420\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 75, Loss= \n",
      " 253.9119\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 76, Loss= \n",
      " 251.6027\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 77, Loss= \n",
      " 250.2230\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 78, Loss= \n",
      " 249.6066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 79, Loss= \n",
      " 249.1756\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 80, Loss= \n",
      " 246.4340\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 81, Loss= \n",
      " 242.3017\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 82, Loss= \n",
      " 243.9097\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 83, Loss= \n",
      " 238.3291\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 84, Loss= \n",
      " 242.2111\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 85, Loss= \n",
      " 240.3633\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 86, Loss= \n",
      " 236.7784\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 87, Loss= \n",
      " 233.4350\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 88, Loss= \n",
      " 234.4707\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 89, Loss= \n",
      " 235.7384\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 90, Loss= \n",
      " 233.4489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 91, Loss= \n",
      " 231.1142\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 92, Loss= \n",
      " 230.3744\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 93, Loss= \n",
      " 229.5680\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 94, Loss= \n",
      " 230.3966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 95, Loss= \n",
      " 226.2371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 96, Loss= \n",
      " 225.4959\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 97, Loss= \n",
      " 227.0798\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 98, Loss= \n",
      " 225.7567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 99, Loss= \n",
      " 222.1181\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 100, Loss= \n",
      " 223.5336\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 101, Loss= \n",
      " 218.9824\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 102, Loss= \n",
      " 220.3418\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 103, Loss= \n",
      " 215.7507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 104, Loss= \n",
      " 217.5272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 105, Loss= \n",
      " 215.0699\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 106, Loss= \n",
      " 215.9092\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 107, Loss= \n",
      " 216.6474\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 108, Loss= \n",
      " 211.4425\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 109, Loss= \n",
      " 210.7544\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 110, Loss= \n",
      " 215.0592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 111, Loss= \n",
      " 210.3551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 112, Loss= \n",
      " 209.7728\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 113, Loss= \n",
      " 206.7685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 114, Loss= \n",
      " 208.1998\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 115, Loss= \n",
      " 207.1646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 116, Loss= \n",
      " 204.4596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 117, Loss= \n",
      " 207.3736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 118, Loss= \n",
      " 203.6755\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 119, Loss= \n",
      " 205.7501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 120, Loss= \n",
      " 204.0895\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 121, Loss= \n",
      " 200.4096\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 122, Loss= \n",
      " 200.4347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 123, Loss= \n",
      " 199.5378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 124, Loss= \n",
      " 197.4711\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 125, Loss= \n",
      " 199.1939\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 126, Loss= \n",
      " 197.4945\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 127, Loss= \n",
      " 195.6932\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 128, Loss= \n",
      " 196.2252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 129, Loss= \n",
      " 194.9691\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 130, Loss= \n",
      " 194.9861\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 131, Loss= \n",
      " 190.8296\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 132, Loss= \n",
      " 193.4174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 133, Loss= \n",
      " 190.0397\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 134, Loss= \n",
      " 193.1994\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 135, Loss= \n",
      " 187.6848\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 136, Loss= \n",
      " 188.8498\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 137, Loss= \n",
      " 189.5513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 138, Loss= \n",
      " 186.3190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 139, Loss= \n",
      " 187.1971\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 140, Loss= \n",
      " 186.4279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 141, Loss= \n",
      " 186.0507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 142, Loss= \n",
      " 184.1064\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 143, Loss= \n",
      " 182.7838\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 144, Loss= \n",
      " 186.1609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 145, Loss= \n",
      " 184.0881\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 146, Loss= \n",
      " 179.9164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 147, Loss= \n",
      " 184.3304\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 148, Loss= \n",
      " 180.0872\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 149, Loss= \n",
      " 181.0996\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 150, Loss= \n",
      " 178.1594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 151, Loss= \n",
      " 177.8752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 152, Loss= \n",
      " 177.5010\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 153, Loss= \n",
      " 178.4827\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 154, Loss= \n",
      " 175.9093\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 155, Loss= \n",
      " 173.9634\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 156, Loss= \n",
      " 174.7346\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 157, Loss= \n",
      " 174.5659\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 158, Loss= \n",
      " 173.9917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 159, Loss= \n",
      " 172.9852\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 160, Loss= \n",
      " 173.7877\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 161, Loss= \n",
      " 171.9242\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 162, Loss= \n",
      " 174.0354\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 163, Loss= \n",
      " 171.2347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 164, Loss= \n",
      " 169.0376\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 165, Loss= \n",
      " 171.4754\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 166, Loss= \n",
      " 167.9464\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 167, Loss= \n",
      " 167.8337\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 168, Loss= \n",
      " 166.6727\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 169, Loss= \n",
      " 163.8553\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 170, Loss= \n",
      " 166.5708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 171, Loss= \n",
      " 168.1848\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 172, Loss= \n",
      " 168.0514\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 173, Loss= \n",
      " 164.8902\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 174, Loss= \n",
      " 166.6802\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 175, Loss= \n",
      " 164.1909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 176, Loss= \n",
      " 163.5671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 177, Loss= \n",
      " 162.2834\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 178, Loss= \n",
      " 163.3182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 179, Loss= \n",
      " 160.7724\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 180, Loss= \n",
      " 160.7331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 181, Loss= \n",
      " 163.6302\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 182, Loss= \n",
      " 165.1332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 183, Loss= \n",
      " 161.3400\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 184, Loss= \n",
      " 161.1032\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 185, Loss= \n",
      " 159.9461\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 186, Loss= \n",
      " 160.7451\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 187, Loss= \n",
      " 160.8635\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 188, Loss= \n",
      " 158.8384\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 189, Loss= \n",
      " 158.6206\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 190, Loss= \n",
      " 156.2379\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 191, Loss= \n",
      " 159.2542\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 192, Loss= \n",
      " 154.3829\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 193, Loss= \n",
      " 155.0813\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 194, Loss= \n",
      " 152.3582\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 195, Loss= \n",
      " 153.2630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 196, Loss= \n",
      " 151.0636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 197, Loss= \n",
      " 154.3895\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 198, Loss= \n",
      " 153.9508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 199, Loss= \n",
      " 153.1750\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 200, Loss= \n",
      " 151.8537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 201, Loss= \n",
      " 152.4613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 202, Loss= \n",
      " 149.1811\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 203, Loss= \n",
      " 149.6156\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 204, Loss= \n",
      " 151.7594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 205, Loss= \n",
      " 149.4124\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 206, Loss= \n",
      " 149.6268\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 207, Loss= \n",
      " 147.0226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 208, Loss= \n",
      " 148.0070\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 209, Loss= \n",
      " 151.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 210, Loss= \n",
      " 149.1367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 211, Loss= \n",
      " 147.4196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 212, Loss= \n",
      " 149.8448\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 213, Loss= \n",
      " 149.2984\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 214, Loss= \n",
      " 147.8685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 215, Loss= \n",
      " 147.2408\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 216, Loss= \n",
      " 146.3580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 217, Loss= \n",
      " 145.7733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 218, Loss= \n",
      " 145.7220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 219, Loss= \n",
      " 143.2745\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 220, Loss= \n",
      " 143.7932\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 221, Loss= \n",
      " 145.4309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 222, Loss= \n",
      " 141.7955\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 223, Loss= \n",
      " 141.1317\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 224, Loss= \n",
      " 142.8400\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 225, Loss= \n",
      " 142.4561\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 226, Loss= \n",
      " 141.2629\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 227, Loss= \n",
      " 139.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 228, Loss= \n",
      " 144.3591\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 229, Loss= \n",
      " 142.5817\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 230, Loss= \n",
      " 140.1920\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 231, Loss= \n",
      " 141.6827\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 232, Loss= \n",
      " 141.4057\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 233, Loss= \n",
      " 140.0054\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 234, Loss= \n",
      " 141.2632\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 235, Loss= \n",
      " 141.5096\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 236, Loss= \n",
      " 136.1134\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 237, Loss= \n",
      " 139.1402\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 238, Loss= \n",
      " 140.0102\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 239, Loss= \n",
      " 136.1251\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 240, Loss= \n",
      " 139.6681\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 241, Loss= \n",
      " 136.5415\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 242, Loss= \n",
      " 139.3929\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 243, Loss= \n",
      " 136.0698\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 244, Loss= \n",
      " 133.8127\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 245, Loss= \n",
      " 137.7026\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 246, Loss= \n",
      " 137.8862\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 247, Loss= \n",
      " 137.3954\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 248, Loss= \n",
      " 130.0921\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 249, Loss= \n",
      " 136.1913\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 250, Loss= \n",
      " 132.1453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 251, Loss= \n",
      " 133.1720\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 252, Loss= \n",
      " 135.3734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 253, Loss= \n",
      " 134.6627\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 254, Loss= \n",
      " 132.7222\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 255, Loss= \n",
      " 132.2436\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 256, Loss= \n",
      " 129.5532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 257, Loss= \n",
      " 132.1914\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 258, Loss= \n",
      " 132.2992\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 259, Loss= \n",
      " 129.7943\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 260, Loss= \n",
      " 132.0534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 261, Loss= \n",
      " 133.3797\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 262, Loss= \n",
      " 130.4857\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 263, Loss= \n",
      " 127.0062\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 264, Loss= \n",
      " 126.9401\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 265, Loss= \n",
      " 129.3328\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 266, Loss= \n",
      " 132.6869\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 267, Loss= \n",
      " 129.4552\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 268, Loss= \n",
      " 127.9245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 269, Loss= \n",
      " 128.1546\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 270, Loss= \n",
      " 129.3761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 271, Loss= \n",
      " 128.4238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 272, Loss= \n",
      " 124.8363\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 273, Loss= \n",
      " 127.3605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 274, Loss= \n",
      " 129.9822\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 275, Loss= \n",
      " 129.3983\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 276, Loss= \n",
      " 126.2435\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 277, Loss= \n",
      " 129.6061\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 278, Loss= \n",
      " 124.2837\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 279, Loss= \n",
      " 126.6221\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 280, Loss= \n",
      " 125.9723\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 281, Loss= \n",
      " 127.5546\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 282, Loss= \n",
      " 124.6740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 283, Loss= \n",
      " 123.1957\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 284, Loss= \n",
      " 126.2499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 285, Loss= \n",
      " 125.5723\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 286, Loss= \n",
      " 128.0258\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 287, Loss= \n",
      " 125.1387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 288, Loss= \n",
      " 125.8462\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 289, Loss= \n",
      " 126.1243\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 290, Loss= \n",
      " 122.4529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 291, Loss= \n",
      " 123.8065\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 292, Loss= \n",
      " 123.5956\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 293, Loss= \n",
      " 120.8387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 294, Loss= \n",
      " 123.1363\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 295, Loss= \n",
      " 120.2910\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 296, Loss= \n",
      " 121.3387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 297, Loss= \n",
      " 119.1850\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 298, Loss= \n",
      " 120.6625\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch: 299, Loss= \n",
      " 121.7610\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ntopk=3\n",
    "predict=torch.LongTensor(train_batches*batch_size,ntopk).zero_()\n",
    "all_targets=torch.LongTensor(train_batches*batch_size).zero_()\n",
    "for epoch in xrange(no_epochs):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    train_iter=iter(train_loader)\n",
    "    for batch in xrange(train_batches):\n",
    "        context_idxs=[]\n",
    "        cats=[]\n",
    "        # Step 1. Prepare the inputs to be passed to the model.  To do this we will:\n",
    "        #  iterate around each sentance in the batch creating a numerical array of the \n",
    "        #  word indecies\n",
    "        inputs,targets=train_iter.next()\n",
    "        t_inputs=autograd.Variable(inputs)\n",
    "        t_targets=autograd.Variable(targets)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(t_inputs)\n",
    "        _,ind=log_probs.data.topk(3,1,True,True)\n",
    "        if epoch==no_epochs-1:\n",
    "            predict[batch*batch_size:(batch+1)*batch_size,:]=ind\n",
    "            all_targets[batch*batch_size:(batch+1)*batch_size]=targets\n",
    "        loss=loss_function(log_probs, t_targets)\n",
    "        #print \"Batch: {0}, Loss= {1}\".format(batch,loss.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.data\n",
    "    print \"Epoch: {0}, Loss= {1}\".format(epoch,total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error:  \n",
      " 121.7610\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training accuracy:  [\n",
      " 89.0625\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 98.6060\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print \"Training error: \", total_loss\n",
    "train_res=accuracy(predict,all_targets,topk=(1,3))\n",
    "print \"Training accuracy: \", train_res   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  0 :  87.40 % from a population of 3103\n",
      "Accuracy of  1 :  75.68 % from a population of 148\n",
      "Accuracy of  2 :  83.05 % from a population of  59\n",
      "Accuracy of  3 :  77.15 % from a population of 827\n",
      "Accuracy of  4 :   0.00 % from a population of  11\n",
      "Accuracy of  5 :  92.97 % from a population of 725\n",
      "Accuracy of  6 :   0.00 % from a population of   6\n",
      "Accuracy of  7 :  93.14 % from a population of 102\n",
      "Accuracy of  8 :  78.69 % from a population of 244\n",
      "Accuracy of  9 :  95.81 % from a population of 4227\n",
      "Accuracy of 10 :  90.73 % from a population of 561\n",
      "Accuracy of 11 :  89.88 % from a population of 336\n",
      "Accuracy of 12 :  88.83 % from a population of 573\n",
      "Accuracy of 13 :  83.69 % from a population of 2134\n",
      "Total training cases: 13056, Vocab: 3508\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(len(label_to_idx)))\n",
    "class_total = list(0. for i in range(len(label_to_idx)))\n",
    "for i in range(len(predict)):\n",
    "    c = (predict[i][0] == all_targets[i])\n",
    "    label = all_targets[i]\n",
    "    class_correct[label] += c\n",
    "    class_total[label] += 1\n",
    "\n",
    "for i in range(len(label_to_idx)):\n",
    "    #print 'Accuracy of {0}'.format(label_to_idx[0])\n",
    "    if class_total[i]>0:\n",
    "        acc=(100 * class_correct[i] / class_total[i])\n",
    "    else:\n",
    "        acc=0\n",
    "    print 'Accuracy of {0:2d} : {1:6.2f} % from a population of {2:3d}'.format(\n",
    "        i, acc, int(class_total[i]))\n",
    "print 'Total training cases: {0}, Vocab: {1}'.format(len(predict),vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation total loss, Loss= \n",
      " 20.3725\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntopk=3\n",
    "val_predict=torch.LongTensor(val_batches*batch_size,ntopk).zero_()\n",
    "val_targets=torch.LongTensor(val_batches*batch_size).zero_()\n",
    "val_total_loss = torch.Tensor([0])\n",
    "val_iter=iter(val_loader)\n",
    "v_total_loss=0\n",
    "for batch in xrange(val_batches):\n",
    "    context_idxs=[]\n",
    "    cats=[]\n",
    "    inputs,targets=val_iter.next()\n",
    "    model.eval()\n",
    "    #bp() # This is a breakpoint.\n",
    "    vinputs = autograd.Variable(inputs)\n",
    "    #targets=autograd.Variable(torch.LongTensor(np.asarray(cats,dtype='int64')).view(batch_size,-1))\n",
    "    vtargets=autograd.Variable(targets)\n",
    "    log_probs = model(vinputs)\n",
    "    _,ind=log_probs.data.topk(3,1,True,True)\n",
    "    val_predict[batch*batch_size:(batch+1)*batch_size,:]=ind\n",
    "    val_targets[batch*batch_size:(batch+1)*batch_size]=targets\n",
    "    loss=loss_function(log_probs, vtargets)\n",
    "    #print \"Batch: {0}, Loss= {1}\".format(batch,loss.data)\n",
    "    v_total_loss+=loss.data\n",
    "print \"Validation total loss, Loss= {0}\".format(v_total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  [\n",
      " 92.1420\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 99.3325\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    " # Test accuracy\n",
    "test_res=accuracy(val_predict,val_targets,topk=(1,3))\n",
    "print \"Test accuracy: \", test_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Activity             :  92.90 %% from a population of 746\n",
      "Accuracy of Course               :  76.74 %% from a population of  43\n",
      "Accuracy of Exam resit           : 100.00 %% from a population of  13\n",
      "Accuracy of Fees or contribution :  75.60 %% from a population of 209\n",
      "Accuracy of Letting              :   0.00 %% from a population of   3\n",
      "Accuracy of Meal                 :  94.33 %% from a population of 194\n",
      "Accuracy of Patents evening      :   0.00 %% from a population of   2\n",
      "Accuracy of School bus           : 100.00 %% from a population of  29\n",
      "Accuracy of Tickets              :  77.59 %% from a population of  58\n",
      "Accuracy of Trip                 :  98.10 %% from a population of 1055\n",
      "Accuracy of Tuition              :  95.86 %% from a population of 169\n",
      "Accuracy of Uniform              :  97.50 %% from a population of  80\n",
      "Accuracy of Wraparound care      :  90.54 %% from a population of 148\n",
      "Accuracy of Other                :  86.65 %% from a population of 547\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(len(label_to_idx)))\n",
    "class_total = list(0. for i in range(len(label_to_idx)))\n",
    "for i in range(len(val_predict)):\n",
    "    c = (val_predict[i][0] == val_targets[i])\n",
    "    label = val_targets[i]\n",
    "    class_correct[label] += c\n",
    "    class_total[label] += 1\n",
    "\n",
    "for i in range(len(label_to_idx)):\n",
    "    #print 'Accuracy of {0}'.format(label_to_idx[0])\n",
    "    if class_total[i]>0:\n",
    "        acc=(100 * class_correct[i] / class_total[i])\n",
    "    else:\n",
    "        acc=0\n",
    "    label=label_to_idx.keys()[label_to_idx.values().index(i)]\n",
    "    print 'Accuracy of {0:20s} : {1:6.2f} %% from a population of {2:3d}'.format(\n",
    "        label, acc, int(class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
